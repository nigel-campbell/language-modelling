{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2824, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-b2c6d87b5834>\", line 14, in <module>\n",
      "    get_ipython().magic(u'matplotlib inline')\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2160, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2081, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-105>\", line 2, in matplotlib\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/magics/pylab.py\", line 100, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2966, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/ncampbell7/anaconda2/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import data\n",
    "\n",
    "# Assuming that you have completed training the classifer, let us plot the training loss vs. iteration. This is an\n",
    "# example to show a simple way to log and plot data from PyTorch.\n",
    "\n",
    "# we neeed matplotlib to plot the graphs for us!\n",
    "import matplotlib\n",
    "# This is needed to save images \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "path = './data/2013.txt'\n",
    "corpus = data.Corpus(path, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_LanguageModel(nn.Module):\n",
    "        \n",
    "    def __init__(self, vocab_size, embed_size, nhidden, nlayers):\n",
    "        super(LSTM_LanguageModel, self).__init__()\n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, nhidden, nlayers)\n",
    "        self.decoder = nn.Linear(nhidden, vocab_size)\n",
    "\n",
    "    def forward(self, x, h0):\n",
    "        y = self.encoder(x)\n",
    "        y = y.unsqueeze(0)\n",
    "        y, h1 = self.rnn(y, h0)\n",
    "        y = self.decoder(y)\n",
    "        return y, h1\n",
    "\n",
    "class RNN_LanguageModel(nn.Module):\n",
    "        \n",
    "    def __init__(self, vocab_size, embed_size, nhidden, nlayers):\n",
    "        super(RNN_LanguageModel, self).__init__()\n",
    "        self.encoder = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, nhidden, nlayers)\n",
    "        self.decoder = nn.Linear(nhidden, vocab_size)\n",
    "\n",
    "    def forward(self, x, h0):\n",
    "        y = self.encoder(x)\n",
    "        y = y.unsqueeze(0)\n",
    "        y, h1 = self.rnn(y, h0)\n",
    "        y = self.decoder(y)\n",
    "        return y, h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_LanguageModel(\n",
       "  (encoder): Embedding(27738, 200)\n",
       "  (rnn): RNN(200, 10, num_layers=2)\n",
       "  (decoder): Linear(in_features=10, out_features=27738, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(corpus)\n",
    "embed_size = 200\n",
    "nhidden = 10\n",
    "nlayers = 2\n",
    "lm = RNN_LanguageModel(vocab_size, embed_size, nhidden, nlayers)\n",
    "lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_LanguageModel(\n",
       "  (encoder): Embedding(27738, 200)\n",
       "  (rnn): RNN(200, 10, num_layers=2)\n",
       "  (decoder): Linear(in_features=10, out_features=27738, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_lm = LSTM_LanguageModel(vocab_size, embed_size, nhidden, nlayers)\n",
    "lstm_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Validating RNN.\n",
    "batch_size = 5\n",
    "x0 = torch.tensor([0,1,2,3,5])\n",
    "h0 = torch.zeros((nlayers, batch_size, nhidden))\n",
    "x1, h1 = lm(x0, h0)\n",
    "lm(corpus.data[:batch_size].to(torch.long), h0)\n",
    "\n",
    "for p in lm.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "x0 = torch.tensor([0,1,10,3,5])\n",
    "h0 = torch.zeros((nlayers, batch_size, nhidden))\n",
    "lstm_lm.zero_grad()\n",
    "x1, h1 = lstm_lm(x0, h0)\n",
    "lstm_lm(corpus.data[:batch_size].to(torch.long), h0)\n",
    "\n",
    "for p in lstm_lm.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Converts sequence to tensor.\n",
    "'''\n",
    "def seq2ix(seq, corpus):\n",
    "    sequence = [corpus.word2ix[val] for val in seq.split()]\n",
    "    return torch.tensor(sequence)\n",
    "\n",
    "'''\n",
    "Converts tensor output to actual words.\n",
    "'''\n",
    "def ix2word(data, corpus):\n",
    "    to_word = lambda val, corpus: corpus.ix2word[val]\n",
    "    return map(lambda x: to_word(x, corpus), data)\n",
    "\n",
    "\n",
    "def batch(data, i, length):\n",
    "    source = data[i:i+length]\n",
    "    target = data[i+1:i+length+1].to(torch.long)\n",
    "    return source, target\n",
    "\n",
    "'''\n",
    "Runs a single training epoch on the dataset.\n",
    "\n",
    "Warning: One EPOCH took\n",
    "CPU times: user 2min 45s, sys: 40.5 s, total: 3min 26s\n",
    "Definitely needs to be trained on ICEHAMMER GPUs.\n",
    "'''\n",
    "def train(lm, corpus, seq_length, criterion=nn.CrossEntropyLoss(), lr=0.01, momentum=0.9, start = 0):\n",
    "    lm.train()\n",
    "    optimizer = torch.optim.SGD(lm.parameters(), lr=lr, momentum=momentum)\n",
    "    total_loss = 0.\n",
    "    data = corpus.data\n",
    "    length = data.size(0)\n",
    "    iterations = 1\n",
    "    for i in range(start, length-seq_length, seq_length):\n",
    "        lm.zero_grad()\n",
    "        source, targets = batch(data, i, seq_length)\n",
    "        source = source.to(torch.long)\n",
    "        h0 = torch.zeros((nlayers, source.size(0), nhidden)) #TODO Come up with better initial hidden\n",
    "        output, hidden = lm(source, h0)\n",
    "        output = output.squeeze()\n",
    "        loss = criterion(output, targets)\n",
    "        total_loss += loss.item()\n",
    "        iterations += 1\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    return total_loss / iterations\n",
    "\n",
    "def fit(lm, epochs, seq_length = 15):\n",
    "    loss_history = []\n",
    "    print(\"Running for {} epochs\".format(epochs))\n",
    "    for epoch in range(epochs):\n",
    "        loss = train(lm, corpus, seq_length)\n",
    "        print(\"Loss {}, Epoch {}\".format(loss, epoch))\n",
    "        loss_history.append(loss)\n",
    "    return loss_history\n",
    "\n",
    "def generate(lm, words, corpus):\n",
    "    sentence = []\n",
    "    for word in words.split():\n",
    "        x0 = seq2ix(word, corpus)\n",
    "        batch_size = x0.size(0)\n",
    "        h0 = torch.zeros((nlayers, batch_size, nhidden))\n",
    "        x1, h1 = lm(x0, h0)\n",
    "        word = torch.multinomial(x1.div(1).exp(), 1).squeeze()\n",
    "        sentence.extend(ix2word([word], corpus))\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 5 epochs\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "%time loss_history = fit(lm, epochs)\n",
    "if len(loss_history) > 1: # No need to plot if only one epoch of loss\n",
    "    plt.plot(loss_history)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training loss history')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "%time loss_history = fit(lstm_lm, epochs)\n",
    "print(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have Have'"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(\"Hello world\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
